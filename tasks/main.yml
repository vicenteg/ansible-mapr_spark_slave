---
# tasks file for sparkslave

# Assumes the MapR repos are already configured.

- name: install mapr-spark for RedHat/CentOS
  yum: name='{{item}}' state=present
  with_items:
    - mapr-spark
  when: ansible_distribution in ("CentOS", "RedHat", "Amazon")
  environment: proxy_env

- name: install mapr-spark for Debian/Ubuntu
  apt: name='{{item}}' state=present
  with_items:
    - mapr-spark
  when: ansible_distribution == "Debian" or ansible_distribution == "Ubuntu"
  environment: proxy_env

- name: set spark work directory in spark configuration
  lineinfile: dest=/opt/mapr/spark/spark-{{spark_version}}/conf/spark-env.sh state=present regexp="^export SPARK_WORKER_DIR" line="export SPARK_WORKER_DIR={{spark_work_dir}}"

- name: create a spark work directory
  file: dest={{spark_work_dir}} owner=mapr group=mapr state=directory mode=0750

- name: check whether a local spark volume exists
  command: maprcli volume list -columns volumename -noheader
  ignore_errors: true
  register: maprcli_volume

# - debug: msg="{{maprcli_volume.stdout_lines|map('trim')|list}}"

- name: create a local volume for spark work directory
  command: maprcli volume create -path /var/mapr/local/{{ansible_hostname}}/spark -replication 1 -minreplication 1 -name mapr.{{ansible_hostname}}.local.spark -createparent true
  when: "maprcli_volume is defined and maprcli_volume.stdout.find('mapr.{{ansible_hostname}}.local.spark') == -1"
