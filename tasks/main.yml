---
# tasks file for sparkslave

# Assumes the MapR repos are already configured.

- name: install mapr-spark for RedHat/CentOS
  sudo_user: root
  yum: name='{{item}}-{{spark_version}}.{{spark_build}}' state=present
  with_items:
    - mapr-spark
  when: ansible_distribution in ("CentOS", "RedHat", "Amazon")
  environment: proxy_env

- name: install mapr-spark for Debian/Ubuntu
  sudo_user: root
  apt: name='{{item}}-{{spark_version}}.{{spark_build}}' state=present
  with_items:
    - mapr-spark
  when: ansible_distribution in ("Debian", "Ubuntu")
  environment: proxy_env

- name: set spark work directory in spark configuration
  lineinfile: dest=/opt/mapr/spark/spark-{{spark_version}}/conf/spark-env.sh state=present regexp="^export SPARK_WORKER_DIR" line="export SPARK_WORKER_DIR={{spark_work_dir}}"

- name: create a spark work directory
  sudo_user: root
  file: dest={{spark_work_dir}} owner={{mapr_admin_username}} group={{mapr_admin_username}} state=directory mode=0750

#- name: check whether a local spark volume exists
#  sudo_user: '{{mapr_admin_username}}'
#  command: maprcli volume list -columns volumename -noheader
#  ignore_errors: true
#  register: maprcli_volume

# - debug: msg="{{maprcli_volume.stdout_lines|map('trim')|list}}"

- name: create a local volume for spark work directory
  mapr_volume: 
  args:
    name: mapr.{{ansible_hostname}}.local.spark
    path: /var/mapr/local/{{ansible_hostname}}/spark
    createparent: true
    replication: "1"
    minreplication: "1"
    localvolumehost: '{{ansible_hostname}}'
    mapr_webserver: '{{mapr_webserver}}'
    state: present

#- name: create a local volume for spark work directory
#  mapr_volume: name=mapr.{{ansible_hostname}}.local.spark path=/var/mapr/local/{{ansible_hostname}}/spark createparent=true replication=1 minreplication=1 localvolumehost={{ansible_hostname}} mapr_webserver={{mapr_webserver}}
#  when: "maprcli_volume is defined and maprcli_volume.stdout.find('mapr.{{ansible_hostname}}.local.spark') == -1"
